---
title: "Practica 2"
author: "Brais Santos Negreira / Jorge Álvarez Gracia"
date: "Diciembre 2021"
output: 
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
---

******

# Detalles de la actividad

## Descripción
Rellenar

## Objetivos

Rellenar

## Competencias

Rellenar

#  Introducción

## Elección del DataSet

******

El conjunto de datos que hemos elegido está en la siguiente url: https://www.kaggle.com/fedesoriano/heart-failure-prediction. Se ha escogido ya que es una temática muy interesante las enfermedades cardiovasculares y al mismo tiempo comprobamos que haya campos numéricos y categóricos. Lo que pretende responder es como afecta o no las enfermedades cardiovasculares en función de las caracterísitcas de las personas.


******
## Carga del dataset

******

Se lee el fichero "heart.csv".
```{r,eval=TRUE,echo=TRUE}

heart <- read.csv("heart.csv",sep=",")

```


## Explicación de las variables
A continuación, obtenemos el listado de variables:

```{r,eval=TRUE,echo=TRUE}

str(heart)

```

<li> __Age__ : edad del paciente.</li> 
<li> __Sex__ : sexo del paciente. </li> 
<li> __ChestPainType__ : Tipo de dolor del pecho. </li>
<li> __RestingBP__ : presión arterial en reposo (sistólica). </li>
<li> __Cholesterol__ : colesterol sérico. </li>
<li> __FastingBS__ : azúcar en sangre en ayunas.</li>
<li> __RestingECG__: resultados del electrocardiograma en reposo. </li>
<li> __MaxHR__: frecuencia cardíaca máxima alcanzada. </li>
<li> __ExerciseAngina__: angina inducida por el ejercicio. </li>
<li> __Oldpeak__ : ejercicio inducido por la depresión (ST) en relación con el descanso. </li>
<li> __ST_Slope__ : pendiente del segmento ST del ejercicio pico. </li>
<li> __HeartDisease__   : clase de salida. </li>

<br>
Se muestra un resumen de las variables.

```{r,eval=TRUE,echo=TRUE}

summary(heart)

```

A partir de esto, se puede concluir con que hay 12 variables y 918 observaciones. También se aprecia que en el dataset hay 3 tipos de datos:

<li> Variables numéricas: Oldpeak. </li>
<li> Variables de tipo carácter: Sex, ChestPainType, RestingECG, ExerciseAngina, ST_Slope. </li>
<li> Variables de tipo entero: Age, RestingBP, Cholesterol, FastingBS, MaxHR, HeartDisease. </li>

## Importancia y objetivos de los análisis

# Preprocesado de datos

## Conversión y estandarización

Pasamos los valores int a numeric y los char a factor.

```{r,eval=TRUE,echo=TRUE}

heart$Age <- as.numeric(heart$Age)
heart$Sex <- as.factor(heart$Sex)
heart$ChestPainType <- as.factor(heart$ChestPainType)
heart$RestingBP <- as.numeric(heart$RestingBP)
heart$Cholesterol <- as.numeric(heart$Cholesterol)
heart$FastingBS <- as.numeric(heart$FastingBS)
heart$RestingECG  <- as.factor(heart$RestingECG)
heart$MaxHR <- as.numeric(heart$MaxHR)
heart$ExerciseAngina <- as.factor(heart$ExerciseAngina)
heart$ST_Slope <- as.factor(heart$ST_Slope)
heart$HeartDisease <- as.numeric(heart$HeartDisease)

```


## Estudio de outliers

En este apartado, se va a mostrar el diagrama de cajas de cada una de las variables numéricas para comprobar si hay posibles outliers.

__Age__:

Se aprecia que en la variable "Age" no hay ningún valor extremo.
```{r,eval=TRUE,echo=TRUE}

boxplot(heart$Age,main="Edad del paciente")

```

```{r,eval=TRUE,echo=TRUE}

boxplot.stats(heart$Age)$out

```


__RestingBP__:

En el campo "RestingBP" se observa algunos outliers, pero no se eliminarán debido a que la presión arterial sistólica puede tener valores superiores a 180 (esto sería una crisis de hipertensión).

```{r,eval=TRUE,echo=TRUE}

boxplot(heart$RestingBP,main="Presión arterial en reposo")

```


```{r,eval=TRUE,echo=TRUE}

boxplot.stats(heart$RestingBP)$out

```

__Cholesterol__:

En esta variable se aprecian una serie de valores extremos, pero por el contrario no es extraño ya que un colesterol de 603 se puede tener (https://www.tuotromedico.com/parametros/colesterol-en-sangre-alto.htm), aunque es un valor muy elevado. También se puede tener el valor 100 que es óptimo.
```{r,eval=TRUE,echo=TRUE}

boxplot(heart$Cholesterol,main="Colesterol")

```


```{r,eval=TRUE,echo=TRUE}

boxplot.stats(heart$Cholesterol)$out

```


__MaxHR__ :

Se puede apreciar que hay dos valores extremos: 60 y 63. Esas frecuencias cardíacas __máximas__ son muy bajas y por tanto lo podemos detectar como valores extraños. 
```{r,eval=TRUE,echo=TRUE}

boxplot(heart$MaxHR,main="Frecuencia cardíaca máxima alcanzada")

```

```{r,eval=TRUE,echo=TRUE}

boxplot.stats(heart$MaxHR)$out

```
A continuación, sustituímos esos valores por NA y luego lo trataremos mediante Knn.

```{r,eval=TRUE,echo=TRUE}

posMaxHR <- which(heart$MaxHR==60 | heart$MaxHR==63)


heart$MaxHR[posMaxHR] <- NA


```

Se aplica kNN para ponerle un valor en función de sus vecinos más cercanos.

```{r,eval=TRUE,echo=TRUE}
library(VIM)

MaxHR_new <- kNN(heart,variable="MaxHR",dist_var =c("Age","Sex","ChestPainType","FastingBS","RestingECG","ExerciseAngina","ST_Slope","HeartDisease"),k=3)
MaxHR_new <- MaxHR_new$MaxHR

heart$MaxHR <- MaxHR_new


```

Se comprueba  que en esa posición hay otro valor diferente.

```{r,eval=TRUE,echo=TRUE}

heart$MaxHR[posMaxHR]


```



## Estudio de Valores nulos

Se aprecia que no hay ningun valor NA. 

```{r,eval=TRUE,echo=TRUE}

colSums(is.na(heart))

```
A continuación, comprobaremos si algún campo tiene un valor 0.

```{r,eval=TRUE,echo=TRUE}

colSums(heart == 0)

```
Viendo esto, se puede decir que no tiene sentido que los campos RestingBP y Cholesterol tengan ceros. En este caso, podemos hablar de información perdida.

```{r,eval=TRUE,echo=TRUE}

posRestingBP <- which(heart$RestingBP == 0)

posCholesterol <- which(heart$Cholesterol == 0)

heart$RestingBP[posRestingBP] <- NA

heart$Cholesterol[posCholesterol] <- NA


```

Para esos 0, hemos metido NA ya que es un valor desconocido y ahora miraremos mediante Knn como tratar esos datos.

<br>
Para solucionar estos valores perdidos, vamos a hacer uso de la función knn.

```{r,eval=TRUE,echo=TRUE}



RestingBP_new <- kNN(heart,variable="RestingBP",dist_var =c("Age","Sex","ChestPainType","FastingBS","RestingECG","ExerciseAngina","ST_Slope","HeartDisease"),k=3)
RestingBP_new <- RestingBP_new$RestingBP

heart$RestingBP <- RestingBP_new

Cholesterol_new <- kNN(heart,variable="Cholesterol",dist_var =c("Age","Sex","ChestPainType","FastingBS","RestingECG","ExerciseAngina","ST_Slope","HeartDisease"),k=3)
Cholesterol_new <- Cholesterol_new$Cholesterol

heart$Cholesterol <- Cholesterol_new





```

Se comprueba que ya no hay valores pérdidos en esas posiciones:

```{r,eval=TRUE,echo=TRUE}


heart$RestingBP[posRestingBP]
heart$Cholesterol[posCholesterol]



```

Observamos que los valores NA fueron sustitídos por otros en función de las características de los demás atributos.
<br>
Finalmente, vemos que ya no hay ningun valor perdido.

```{r,eval=TRUE,echo=TRUE}

colSums(is.na(heart))

```


## Normalización 

En este apartado, lo que vamos a hacer es normalizar el campo Age usando min-max. Se creará un nuevo campo llamado Age_nor y se añadirá al dataset.

```{r,eval=TRUE,echo=TRUE}

Age_nor <- (2*(heart$Age-min(heart$Age))/(max(heart$Age)-min(heart$Age)))-1
heart <- cbind(heart,Age_nor)

```

Estos datos, están en el intervalo [-1,1]

```{r,eval=TRUE,echo=TRUE}

min(heart$Age_nor)
max(heart$Age_nor)

```

## Discretización de variables

En esta apartado, también usaremos la variable "Age" para discretizarla en diferentes rangos y se añadirá al dataset con el nombre Age_dis.

```{r,eval=TRUE,echo=TRUE}

Age_dist <- cut(heart$Age, breaks = c(0,40,60,80), labels = c("(0-40]","(40,60]","(60,80]"))

heart <- cbind(heart,Age_dist)

```



# Análisis de los datos

## Análisis descriptivo de las variables

Ahora, tenemos el dataset sin valores vacíos así como nuevas variables normalizadas y discretas.
<br>
Por lo tanto, se muestra un resumen del dataset en el cual podemos ver la media, moda, cuartiles y valores mínimos y máximos en el caso de variables numéricas.
En el caso de los factores, podemos ver el número de ocurrencias que tiene dicho valor.

```{r,eval=TRUE,echo=TRUE}

summary(heart)

```
## Estudio normalidad de las variables

### Comprobación de la normalidad

En este apartado, comprobaremos la normalidad de las variables numéricas, pero las que no son dicotómicas.

__Age__


```{r,eval=TRUE,echo=TRUE}

qqnorm(heart$Age)
qqline(heart$Age)

```

A simple vista, se puede ver que los datos están por la recta menos por los lados y podríamos asumir normalidad. De todas formas comprobaremos esto con el test de shapiro y Lilliefors.

```{r,eval=TRUE,echo=TRUE}

shapiro.test(heart$Age)

```

```{r,eval=TRUE,echo=TRUE}

library(nortest)
lillie.test(heart$Age)

```

Viendo ambos test, se puede apreciar que no sigue una distribucción normal la variable "Age".

__RestingBP__

```{r,eval=TRUE,echo=TRUE}

qqnorm(heart$RestingBP)
qqline(heart$RestingBP)

```

Tal como se aprecia, los valores no suelen estar en la recta y por lo tanto no sigue una distribucción normal.

__Cholesterol__

```{r,eval=TRUE,echo=TRUE}

qqnorm(heart$Cholesterol)
qqline(heart$Cholesterol)

```

Se aprecia que bastantes puntos están muy por fuera de la recta. Con esto, concluímos que el campo Cholesterol no sigue una distribución normal.

__MaxHR__

```{r,eval=TRUE,echo=TRUE}

qqnorm(heart$MaxHR)
qqline(heart$MaxHR)

```

Se observa que los puntos suelen seguir la recta, menos en algunos lados.
<br>
Para estar más seguros aplicamos los test de shapiro y Lilliefors.

```{r,eval=TRUE,echo=TRUE}

shapiro.test(heart$MaxHR)

```
```{r,eval=TRUE,echo=TRUE}

lillie.test(heart$MaxHR)

```

Según ambos test, la variable MaxHR no sigue una distribución normal.

__Oldpeak__

```{r,eval=TRUE,echo=TRUE}

qqnorm(heart$Oldpeak)
qqline(heart$Oldpeak)

```

A simple vista, se observa que muchos puntos están fuera de la recta y con esto podemos decir que no sigue una distribución normal.

__Age_nor__

```{r,eval=TRUE,echo=TRUE}

qqnorm(heart$Age_nor)
qqline(heart$Age_nor)

```

Se aprecia que muchos puntos siguen la recta ( similar a la variable Age sin normalizar ).
<br>
A continuación, aplicamos los siguientes test:

```{r,eval=TRUE,echo=TRUE}

shapiro.test(heart$Age_nor)

```

```{r,eval=TRUE,echo=TRUE}

lillie.test(heart$Age_nor)

```
Nos da la misma información que la variable Age. Por tanto, podemos decir que no sigue una distribución normal.

### Teorema del límite central

Dado que el tamaño de este dataset es >30, se puede decir por el teorema del límite central que las variables mencionadas anteriormente siguen una distribución normal.


## Contraste de hipótesis

### Queremos saber si el colesterol de las mujeres es mayor que el de los hombres

Primero, calculamos dos variables para obtener el colesterol de hombres y mujeres.
```{r,eval=TRUE,echo=TRUE}

colHom <- heart$Cholesterol[heart$Sex=="M"]

colMuj <- heart$Cholesterol[heart$Sex=="F"]

```

Como hipotesis nula, se quiere saber si el colesterol en mujeres es igual que en el de los hombres.
<br>
Como hipotesis alternativa se quiere saber si el colesterol en mujeres es mayor que en hombres.

$$
\left\{
\begin{array}{ll}
H_{0}: &  \mu_M=\mu_H \\
H_{1}: & \mu_M>\mu_H
\end{array}
\right.\\
\ Hipótesis\ unilateral
$$
Por el teorema del límite central, asumimos normalidad ya que tenemos una muestra con n>30. Esto, es un contraste de hipótesis de dos muestras independientes sobre la media (varianzas desconocidas).
Es un test unilateral por la derecha.
<br>

Ahora, comprobamos la homocesdasticidad.


```{r,eval=TRUE,echo=TRUE}

var.test(colMuj, colHom)

```
Se observa que p-value < 0.05. Por tanto, las varianzas no son iguales.
<br>

A continuación, aplicamos el test de este contraste de hipótesis.

```{r,eval=TRUE,echo=TRUE}

t.test( colMuj,colHom , var.equal=FALSE, alternative = "greater")

```

Se aprecia, que p-value < 0.05. Por tanto, se rechaza la hipótesis nula y se acepta la alternativa de que las mujeres tiene más colesterol que los hombres.

### Azúcar en sangre es mayor en hombres que en mujeres teniendo ambos enfermedades cardíacas


Primero, calculamos dos variables para obtener las enfermades cardíacas de hombres y mujeres.
```{r,eval=TRUE,echo=TRUE}

carHom <- heart$FastingBS[heart$Sex=="M" & heart$HeartDisease=="1"]

carMuj <- heart$FastingBS[heart$Sex=="F" & heart$HeartDisease=="1"]

```

Como hipotesis nula, se quiere saber si las enfermades cardíacas es igual en hombres que en mujeres.
<br>
Como hipotesis alternativa se quiere saber si las enfermades cardíacas es mayor en hombres que en mujeres.

$$
\left\{
\begin{array}{ll}
H_{0}: &  \mu_H=\mu_M \\
H_{1}: & \mu_H>\mu_M
\end{array}
\right.\\
\ Hipótesis\ unilateral
$$

Por el teorema del límite central, asumimos normalidad ya que tenemos una muestra con n>30. Esto, es un contraste de hipótesis de dos muestras independientes sobre la media (varianzas desconocidas).
Es un test unilateral por la derecha.
<br>

Ahora, comprobamos la homocesdasticidad.


```{r,eval=TRUE,echo=TRUE}

var.test(carHom,carMuj)

```
Se observa que p-value > 0.05. Por tanto, las varianzas son iguales.
<br>

A continuación, aplicamos el test de este contraste de hipótesis.

```{r,eval=TRUE,echo=TRUE}

t.test( carHom,carMuj , var.equal=TRUE, alternative = "greater")

```

Se aprecia, que p-value > 0.05. Por tanto, se acepta la hipótesis nula de que los hombres con enfermedad cardíaca tienen igual azucar en sangre que las mujeres con enfermedad cardíaca.

## Estudio de correlación entre las variables

En este apartado, representaremos la matriz de correlación del dataset.
<br>
Pasamos todsas las variables a numéricas en un dataset nuevo.
```{r,eval=TRUE,echo=TRUE}

heart_num <-heart[1:12]
heart_num$Sex <- as.numeric(heart_num$Sex)
heart_num$ChestPainType <- as.numeric(heart_num$ChestPainType)
heart_num$RestingECG <- as.numeric(heart_num$RestingECG)
heart_num$ExerciseAngina <- as.numeric(heart_num$ExerciseAngina)
heart_num$ST_Slope <- as.numeric(heart_num$ST_Slope)

```

<br>
Calculamos la correlación de las variables usando el método de pearson.

```{r,eval=TRUE,echo=TRUE}

Corelacion <- cor(heart_num,method="pearson")
Corelacion

```

A continuación, representamos la matriz de correlación.

```{r,eval=TRUE,echo=TRUE}
if (!require('corrplot')) install.packages('corrplot'); library('corrplot')
corrplot(Corelacion, method = "number")

```

A partir de aqui, podemos observar lo siguiente: 
<br>
<li>Las variables HeartDisease y ST_Slope tienen una correlación moderada directa (0.56). </li>
<li>Las variables Oldpeak y ST_Slope tienen una correlación moderada directa (0.50). </li>
<li> Las variables MaxHR y HeartDisease tienen una correlación débil directa (0.40). </li>

## Regresión lineal

### Regresión lineal simple


Se calcula un modelo de regresión lineal simple cuya variable dependiente es MaxHR y independiente es Age.
```{r,eval=TRUE,echo=TRUE}

Model_reg_sim <- lm(MaxHR~Age,data=heart)
summary(Model_reg_sim)

```

Se observa que el coeficiente de determianción ajustado es bajo: 14.6%.

### Regresión lineal múltiple

Se crea un modelo de regresión lineal múltiple con la variable dependiente MaxHR y indpendientes:HeartDisease, ST_Slope, FastingBS, Oldpeak, RestingECG, Sex, Cholesterol.
```{r,eval=TRUE,echo=TRUE}

Model_reg_mul <- lm(MaxHR~Age+HeartDisease+ST_Slope+FastingBS+Oldpeak+RestingECG+Sex+Cholesterol,data=heart)
summary(Model_reg_mul)

```

Se aprecia un coeficiente de determinación bajo (30%).

## Regresión logística

### Regresión logística simple

Vamos a crear una regresión logística simple como variable dependiente HeartDisease y indpendiente MaxHR.

```{r,eval=TRUE,echo=TRUE}

model_logis1 <- glm(formula=HeartDisease~MaxHR,data=heart,family=binomial())
summary(model_logis1)

```

Calculamos la bondad de ajuste usando el test de hoslem.

```{r,eval=TRUE,echo=TRUE}

if (!require('ResourceSelection')) install.packages('ResourceSelection'); library('ResourceSelection')

hoslem.test(heart$HeartDisease,fitted(model_logis1))

```

Se observa que p-value >0.05. Por tanto, el modelo ajusta bien los datos.

### Regresión logística múltiple

Calculamos una regresión logística múltiple con HeartDisease como variable dependiente y ST_Slope, Oldpeak, MaxHR, ChestPainType, RestingBP, Age_nor como variables dependientes

```{r,eval=TRUE,echo=TRUE}

model_logis2 <- glm(formula=HeartDisease~ST_Slope+Oldpeak+MaxHR+ChestPainType+RestingBP+Age_nor,data=heart,family=binomial())
summary(model_logis2)

```
Se aprecia que el AIC es mucho menor y por tanto, el modelo es mejor.
<br>
Calculamos la bondad de ajuste:

```{r,eval=TRUE,echo=TRUE}

hoslem.test(heart$HeartDisease,fitted(model_logis2))

```
Se aprecia que el modelo tiene p-value > 0.05. Por tanto, ajusta bien los datos.

## Modelos de clasificación

```{r,eval=TRUE,echo=TRUE}

head(heart)

```
### Preparación de los datos para el modelo

Nos interesa desordenar los datos para poder elegir registros aleatorios. Guardaremos los datos con el nuevo nombre de: heart_clasification

```{r,eval=TRUE,echo=TRUE}

set.seed(1)
heart_clasification <- heart[sample(nrow(heart)),]

```

Para la futura evaluación del árbol de decisión, es necesario dividir el conjunto de datos en un conjunto de entrenamiento y un conjunto de prueba. El conjunto de entrenamiento es el subconjunto del conjunto original de datos utilizado para construir un primer modelo; y el conjunto de prueba, el subconjunto del conjunto original de datos utilizado para evaluar la calidad del modelo.

Lo más correcto será utilizar un conjunto de datos diferente del que utilizamos para construir el árbol, es decir, un conjunto diferente del de entrenamiento. No hay ninguna proporción fijada con respecto al número relativo de componentes de cada subconjunto, pero la más utilizada acostumbra a ser 2/3 para el conjunto de entrenamiento y 1/3, para el conjunto de prueba.

La variable por la que clasificaremos es HeartDisease, para clasificar si existe riesgo de enfermedad cardíaca o no, y que se sitúa en nuestro en la columna, la 16. De esta forma, tendremos un conjunto de datos para el entrenamiento y uno para la validación

```{r,eval=TRUE,echo=TRUE}

set.seed(666)
y <- heart_clasification[,12] 
X <- heart_clasification[,1:11] 

```

Dividimos el dataset en dos partes diferenciadas, train y test. Podemos crear directamente un rango utilizando el parámetro split_prop

```{r,eval=TRUE,echo=TRUE}

split_prop <- 3 
indexes = sample(1:nrow( heart_clasification), size=floor(((split_prop-1)/split_prop)*nrow(heart_clasification)))
trainx<-X[indexes,]
trainy<-y[indexes]
testx<-X[-indexes,]
testy<-y[-indexes]

```


### Creación del modelo, calidad del modelo y extracción de reglas


```{r,eval=TRUE,echo=TRUE}

if(!require(ggplot2)){
    install.packages('ggplot2', repos='http://cran.us.r-project.org')
    library(ggplot2)
}
if(!require(ggpubr)){
    install.packages('ggpubr', repos='http://cran.us.r-project.org')
    library(ggpubr)
}
if(!require(grid)){
    install.packages('grid', repos='http://cran.us.r-project.org')
    library(grid)
}

if(!require(gridExtra)){
    install.packages('gridExtra', repos='http://cran.us.r-project.org')
    library(gridExtra)
}

if(!require(C50)){
    install.packages('C50', repos='http://cran.us.r-project.org')
    library(C50)
}

library("rpart")       
library("rpart.plot")  

```


Se crea el árbol de decisión usando los datos de entrenamiento:

Utilizaremos dos bibliotecas diferentes, una de ellas es rpart, para crear el árbol de decisión y rpart.plot para representar visualmente nuestro árbol de decisión.

```{r,eval=TRUE,echo=TRUE}

modelo_clasificacion_rpart <- rpart(formula = trainy ~ ., data = trainx, method = "class" )

```

```{r,eval=TRUE,echo=TRUE}

summary(modelo_clasificacion_rpart)

```

Vamos a representar gráficamente el arbol obtenido de dos maneras diferentes:

```{r,eval=TRUE,echo=TRUE}

rpart.plot(modelo_clasificacion_rpart, type=2,extra = 2, under = TRUE, faclen=5,cex=.55) 
rpart.plot(modelo_clasificacion_rpart, type=2,extra = 8, under = TRUE, faclen=5,cex=.55) 

```

En el primer árbol Observamos las tasas de clasificación para cada nodo, expresada como el número de clasificaciones correctas y el número de observaciones en el nodo. En el segundo gráfico observamos la probabilidad por cada clase.


### Predición del modelo

```{r,eval=TRUE,echo=TRUE}

predicted_model <- predict( modelo_clasificacion_rpart, testx, type="class" )
print(sprintf("La precisión del modelo4 es: %.4f %%",100*sum(predicted_model == testy) / length(predicted_model)))

```

Vamos a crear la matriz de confusión

```{r,eval=TRUE,echo=TRUE}

mat_conf<-table(testy,Predicted=predicted_model)
mat_conf

```

```{r,eval=TRUE,echo=TRUE}
if(!require(gmodels)){
    install.packages('gmodels', repos='http://cran.us.r-project.org')
    library(gmodels)
}

CrossTable(testy, predicted_model,prop.chisq  = FALSE, prop.c = FALSE, prop.r =FALSE,dnn = c('Reality', 'Prediction'))

```
añadir: DISCRETIZAR MÁS VARIABLES, ORDENAR VARIABLES SEGÚN EL ANÁLISIS PCA, REALIZAR BOOSTING, OBTENER REGLAS DEL MODELO C50

```{r,eval=TRUE,echo=TRUE}
if(!require(C50)){
    install.packages('C50', repos='http://cran.us.r-project.org')
    library(C50)
}
trainy = as.factor(trainy)
modelo_clasificacion_C50 <- C50::C5.0(trainx, trainy,rules=TRUE,control = C5.0Control(noGlobalPruning = FALSE) )
summary(modelo_clasificacion_C50)

```

Explicar reglas:


```{r,eval=TRUE,echo=TRUE}
predicted_model <- predict( modelo_clasificacion_C50, testx, type="class" )
print(sprintf("La precisión del modelo es: %.4f %%",100*sum(predicted_model == testy) / length(predicted_model)))

```

# Visualización

Vamos a realizar diferentes estudios gráficos para analizar las distintas variables del modelo y las relaciones entre ellas.

Para ello, diferenciaremos entre los tipos de variables continuas y discretas para su análisis y sí fuera necesario transformaremos las variables para su estudio más eficiente. 

```{r,eval=TRUE,echo=TRUE}
head(heart)
```

Variables discretas:

```{r}
library(ggplot2)
ggplot(data=heart,aes(x=Age_dist,fill=(factor(HeartDisease))))+geom_bar() + ggtitle("Enfermedad Cardiaca por grupo de edad(G1)") + labs(x="Edad", colour= "HeartDisease") 


ggplot(data=heart,aes(x=Sex,fill=factor(HeartDisease)))+geom_bar() + ggtitle("Enfermedad Cardiaca por sexo(G2)") + labs(x="sexo", colour= "HeartDisease") 


ggplot(data=heart,aes(x=ChestPainType,fill=factor(HeartDisease)))+geom_bar() + ggtitle("Enfermedad Cardiaca por ChestPainType(G3)") + labs(x="ChestPainType", colour= "HeartDisease") 


ggplot(data=heart,aes(x=RestingECG,fill=factor(HeartDisease)))+geom_bar() + ggtitle("Enfermedad Cardiaca por RestingECG(G4)") + labs(x="RestingECG", colour= "HeartDisease") 

# ExerciseAngina & HeartDisease
ggplot(data=heart,aes(x=ExerciseAngina,fill=factor(HeartDisease)))+geom_bar() + ggtitle("Enfermedad Cardiaca por ExerciseAngina(G5)") + labs(x="ExerciseAngina", colour= "HeartDisease") 

# ST_Slope & HeartDisease
ggplot(data=heart,aes(x=ST_Slope,fill=factor(HeartDisease)))+geom_bar() + ggtitle("Enfermedad Cardiaca por ST_Slope(G6)") + labs(x="ST_Slope", colour= "HeartDisease") 

# FastingBS & HeartDisease
ggplot(data=heart,aes(x=FastingBS,fill=factor(HeartDisease)))+geom_bar() + ggtitle("Enfermedad Cardiaca por FastingBS(G7)") + labs(x="FastingBS", colour= "HeartDisease") 

```

Variables continuas:

EStudiamos la relación entre la variable edad y colesterol, ya que hemos estudiado su relación anteriormente. 

```{r}
# Coresterol & Sexo
ggplot(heart, aes(x =heart$Age, y = heart$Cholesterol)) + geom_point()+
  geom_smooth(method = "loess") 
```
Estudiamos el resto de variables continuas, en relación con su edad y el riesgo o no de sufrir una enfermedad cardíaca:

```{r}
ggplot(heart, aes(RestingBP, Age, colour = HeartDisease)) + 
  geom_point()+ ggtitle("AÑADIR TITULO GRÁFICO") 

ggplot(heart, aes(Cholesterol, Age, colour = HeartDisease)) + 
  geom_point()+ ggtitle("AÑADIR TITULO GRÁFICO") 

ggplot(heart, aes(MaxHR, Age, colour = HeartDisease)) + 
  geom_point() + ggtitle("AÑADIR TITULO GRÁFICO") 

ggplot(heart, aes(Oldpeak, Age, colour = HeartDisease)) + 
  geom_point() + ggtitle("AÑADIR TITULO GRÁFICO") 

```

COMENTAR CONCLUSIONES DE CADA GRÁFICO y añadir más gráficos si fuera necesario

# Conclusiones

añadir
# Recursos

añadir